{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0013ee3b-6a7f-4625-a110-4f122e698925",
   "metadata": {
    "tags": []
   },
   "source": [
    "## initial sagemaker env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c111685-2de7-4321-9e35-8d7c68c3a012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "images_s3uri = 's3://{0}/hunyuan-lora-train/dataset/'.format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4408032-5d2f-4bcf-a3b8-15cf07a88249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "train_image_dir = \"./images\"\n",
    "docker_file_dir = \"./dockerfile\"\n",
    "os.makedirs(train_image_dir, exist_ok=True)\n",
    "os.makedirs(docker_file_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74cd90-9ef6-45a6-a302-f4acdaeaf9a6",
   "metadata": {},
   "source": [
    "## Prepare training datasets and Dockerfile(docker image for training job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d06caf-b626-4369-b563-fb5bced34ff8",
   "metadata": {},
   "source": [
    "#### 准备你自己的png/txt pair 打标文件放到images路径下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef334db1-8bf4-4841-8625-18f3a621f4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./dataset_clear.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./dataset_clear.sh\n",
    "#如果是视频连续帧的打标，最好随机drop一些catiion：\n",
    "\n",
    "\n",
    "percentage=30 ## drop百分比\n",
    "directory=\"./images\"  # 默认在当前目录执行，你可以修改为其他目录\n",
    "\n",
    "# 获取所有的png文件\n",
    "png_files=($(find \"$directory\" -maxdepth 1 -type f -name \"*.png\"))\n",
    "\n",
    "# 计算需要删除的文件数量\n",
    "num_files=${#png_files[@]}\n",
    "num_to_delete=$((num_files * percentage / 100))\n",
    "\n",
    "if [ $num_to_delete -eq 0 ]; then\n",
    "    echo \"No files to delete with the given percentage.\"\n",
    "    exit 0\n",
    "fi\n",
    "\n",
    "# 随机选择要删除的文件\n",
    "files_to_delete=($(shuf -n $num_to_delete -e \"${png_files[@]}\"))\n",
    "\n",
    "# 删除选中的png文件和对应的txt文件\n",
    "for png_file in \"${files_to_delete[@]}\"; do\n",
    "    # 提取文件名（不包含扩展名）\n",
    "    file_name=$(basename \"$png_file\" .png)\n",
    "    \n",
    "    # 构造对应的txt文件名\n",
    "    txt_file=\"${file_name}.txt\"\n",
    "    \n",
    "    # 删除文件\n",
    "    rm \"$directory/$png_file\"\n",
    "    rm \"$directory/$txt_file\"\n",
    "    \n",
    "    echo \"Deleted: $png_file and $txt_file\"\n",
    "done\n",
    "\n",
    "echo \"Deletion completed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1536c989-4d31-4b73-bc4c-a4a077b7b355",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./images/dataset.toml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./images/dataset.toml\n",
    "# resolution, caption_extension, batch_size, num_repeats, enable_bucket, bucket_no_upscale should be set in either general or datasets\n",
    "# otherwise, the default values will be used for each item\n",
    "\n",
    "# general configurations\n",
    "[general]\n",
    "resolution = [720,1280]\n",
    "caption_extension = \".txt\"\n",
    "batch_size = 1\n",
    "enable_bucket = true\n",
    "bucket_no_upscale = false\n",
    "\n",
    "[[datasets]]\n",
    "image_directory = \"/opt/ml/input/data/lora_hunyuan/\"\n",
    "cache_directory = \"/opt/ml/input/data/lora_hunyuan/\"\n",
    "num_repeats = 1 # optional, default is 1. Number of times to repeat the dataset. Useful to balance the multiple datasets with different sizes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c71b24-34db-4e77-85ff-f46af28649eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## prepare train bootstrap scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f92845cb-bad4-4e05-b85d-d565d281b385",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./train_hunyuan_lora.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./train_hunyuan_lora.sh\n",
    "\n",
    "## upgrade lib\n",
    "pip install -U --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "cd /tmp/ && git clone https://github.com/thu-ml/SageAttention.git && cd SageAttention && python setup.py install\n",
    "cd /tmp/ && git clone -b v2.0.1 https://github.com/Dao-AILab/flash-attention.git && cd flash-attention && python setup.py install\n",
    "\n",
    "## download models\n",
    "mkdir -p /tmp/models && cd /tmp/models/\n",
    "git clone https://github.com/Tencent/HunyuanVideo.git\n",
    "huggingface-cli download tencent/HunyuanVideo --local-dir /tmp/models/hunyuan_ckpts\n",
    "\n",
    "#### llava-llama\n",
    "cd /tmp/models/hunyuan_ckpts\n",
    "huggingface-cli download xtuner/llava-llama-3-8b-v1_1-transformers --local-dir ./llava-llama-3-8b-v1_1-transformers\n",
    "\n",
    "#### 只需要llava-llama的text encoder\n",
    "cd /tmp/models/hunyuan_ckpts\n",
    "python /tmp/models/HunyuanVideo/hyvideo/utils/preprocess_text_encoder_tokenizer_utils.py \\\n",
    "       --input_dir /tmp/models/hunyuan_ckpts/llava-llama-3-8b-v1_1-transformers \\\n",
    "       --output_dir /tmp/models/hunyuan_ckpts/text_encoder\n",
    "\n",
    "\n",
    "cd /tmp/models/hunyuan_ckpts\n",
    "huggingface-cli download openai/clip-vit-large-patch14 --local-dir /tmp/models/hunyuan_ckpts/text_encoder_2\n",
    "\n",
    "#### vae\n",
    "mkdir -p /tmp/models/hunyuan_ckpts/vae \\\n",
    "         && cd /tmp/models/hunyuan_ckpts/vae/ \\\n",
    "         && wget https://huggingface.co/tencent/HunyuanVideo/resolve/main/hunyuan-video-t2v-720p/vae/pytorch_model.pt\n",
    "\n",
    "\n",
    "##cache captions & image latents\n",
    "cd /opt/ml/code/\n",
    "python cache_latents.py --dataset_config /opt/ml/input/data/lora_hunyuan/dataset.toml \\\n",
    "                        --vae /tmp/models/hunyuan_ckpts/vae/pytorch_model.pt \\\n",
    "                        --vae_chunk_size 32 --vae_tiling\n",
    "\n",
    "\n",
    "python cache_text_encoder_outputs.py --dataset_config /opt/ml/input/data/lora_hunyuan/dataset.toml  \\\n",
    "                        --text_encoder1 /tmp/models/hunyuan_ckpts/text_encoder \\\n",
    "                        --text_encoder2 /tmp/models/hunyuan_ckpts/text_encoder_2 \\\n",
    "                        --batch_size 16\n",
    "\n",
    "## start train\n",
    "accelerate launch --num_cpu_threads_per_process 1 --mixed_precision bf16 hv_train_network.py \\\n",
    "    --dit /tmp/models/hunyuan_ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt \\\n",
    "    --dataset_config /opt/ml/input/data/lora_hunyuan/dataset.toml --sage_attn --split_attn --mixed_precision bf16 --fp8_base \\\n",
    "    --optimizer_type adamw --learning_rate 6e-4 --lr_scheduler cosine_with_restarts  --gradient_checkpointing  \\\n",
    "    --max_data_loader_n_workers 4 --persistent_data_loader_workers  \\\n",
    "    --network_module networks.lora --network_dim 32 --network_alpha 32 \\\n",
    "    --timestep_sampling sigmoid --discrete_flow_shift 1 \\\n",
    "    --max_train_epochs 300 --save_every_n_epochs 100 --seed 0 \\\n",
    "    --output_dir /opt/ml/model/lora_hunyuan --output_name hunyuan-lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73ceb6b-31ed-46a0-a518-ab2aaf674329",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4c65b11-0fdf-4768-9096-e934f022c153",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./Dockerfile\n",
    "FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:2.6.0-gpu-py312-cu126-ubuntu22.04-sagemaker\n",
    "\n",
    "ENV PATH=\"/opt/ml/code:${PATH}\"\n",
    "ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
    "ENV DEBIAN_FRONTEND noninteractive\n",
    "\n",
    "RUN git clone https://github.com/kohya-ss/musubi-tuner /opt/ml/code\n",
    "RUN pip install --upgrade huggingface_hub\n",
    "\n",
    "WORKDIR /opt/ml/code\n",
    "\n",
    "COPY ./train_hunyuan_lora.sh /opt/ml/code/train_hunyuan_lora.sh\n",
    "RUN pip install -r requirements.txt\n",
    "RUN pip install wandb\n",
    "\n",
    "#RUN cd /tmp/ && git clone https://github.com/thu-ml/SageAttention.git && cd SageAttention && python setup.py install\n",
    "#RUN git clone -b v2.0.1 https://github.com/Dao-AILab/flash-attention.git&&cd flash-attention&&python setup.py install\n",
    "#RUN pip install -U --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469005ba-e788-425b-aadb-c729e576beb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build docker image and push to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f2f9456-cef0-4d30-9996-43ff8365416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "## You should change below region code to the region you used, here sample is use us-west-2\n",
    "!aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-west-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab2244ef-74e1-438d-a176-e48015530eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  11.37MB\n",
      "Step 1/10 : FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:2.6.0-gpu-py312-cu126-ubuntu22.04-sagemaker\n",
      " ---> d540f57b9239\n",
      "Step 2/10 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 25ca7b5f09e5\n",
      "Step 3/10 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 709fe84f7a93\n",
      "Step 4/10 : ENV DEBIAN_FRONTEND noninteractive\n",
      " ---> Using cache\n",
      " ---> 0fe43d2f5952\n",
      "Step 5/10 : RUN git clone https://github.com/kohya-ss/musubi-tuner /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 73745f290baf\n",
      "Step 6/10 : RUN pip install --upgrade huggingface_hub\n",
      " ---> Using cache\n",
      " ---> f94c8a8f4988\n",
      "Step 7/10 : WORKDIR /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 05e07fc6ec4f\n",
      "Step 8/10 : COPY ./train_hunyuan_lora.sh /opt/ml/code/train_hunyuan_lora.sh\n",
      " ---> d18bf306fa6b\n",
      "Step 9/10 : RUN pip install -r requirements.txt\n",
      " ---> Running in 7978f230e246\n",
      "Collecting accelerate==1.6.0 (from -r requirements.txt (line 1))\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting av==14.0.1 (from -r requirements.txt (line 2))\n",
      "  Downloading av-14.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting bitsandbytes==0.45.4 (from -r requirements.txt (line 3))\n",
      "  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting diffusers==0.32.1 (from -r requirements.txt (line 4))\n",
      "  Downloading diffusers-0.32.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting einops==0.7.0 (from -r requirements.txt (line 5))\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting huggingface-hub==0.30.0 (from -r requirements.txt (line 6))\n",
      "  Downloading huggingface_hub-0.30.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting opencv-python==4.10.0.84 (from -r requirements.txt (line 7))\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (11.1.0)\n",
      "Collecting safetensors==0.4.5 (from -r requirements.txt (line 9))\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting toml==0.10.2 (from -r requirements.txt (line 10))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (4.67.1)\n",
      "Collecting transformers==4.46.3 (from -r requirements.txt (line 12))\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting voluptuous==0.15.2 (from -r requirements.txt (line 13))\n",
      "  Downloading voluptuous-0.15.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting ftfy==6.3.1 (from -r requirements.txt (line 16))\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting easydict==1.13 (from -r requirements.txt (line 17))\n",
      "  Downloading easydict-1.13-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/site-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/site-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/site-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/site-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/site-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (2.6.0+cu126)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/site-packages (from diffusers==0.32.1->-r requirements.txt (line 4)) (6.11.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from diffusers==0.32.1->-r requirements.txt (line 4)) (3.17.0)\n",
      "Collecting regex!=2019.12.17 (from diffusers==0.32.1->-r requirements.txt (line 4))\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/site-packages (from diffusers==0.32.1->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/site-packages (from huggingface-hub==0.30.0->-r requirements.txt (line 6)) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/site-packages (from huggingface-hub==0.30.0->-r requirements.txt (line 6)) (4.12.2)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.3->-r requirements.txt (line 12))\n",
      "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/site-packages (from ftfy==6.3.1->-r requirements.txt (line 16)) (0.2.13)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (80.4.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.12/site-packages (from importlib-metadata->diffusers==0.32.1->-r requirements.txt (line 4)) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests->diffusers==0.32.1->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests->diffusers==0.32.1->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests->diffusers==0.32.1->-r requirements.txt (line 4)) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests->diffusers==0.32.1->-r requirements.txt (line 4)) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (3.0.2)\n",
      "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Downloading av-14.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.2/34.2 MB 172.5 MB/s eta 0:00:00\n",
      "Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.0/76.0 MB 163.6 MB/s eta 0:00:00\n",
      "Downloading diffusers-0.32.1-py3-none-any.whl (3.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 114.0 MB/s eta 0:00:00\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "Downloading huggingface_hub-0.30.0-py3-none-any.whl (481 kB)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.5/62.5 MB 181.7 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (434 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.0/10.0 MB 143.9 MB/s eta 0:00:00\n",
      "Downloading voluptuous-0.15.2-py3-none-any.whl (31 kB)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Downloading easydict-1.13-py3-none-any.whl (6.8 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 796.9/796.9 kB 47.4 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 131.8 MB/s eta 0:00:00\n",
      "Installing collected packages: easydict, voluptuous, toml, safetensors, regex, opencv-python, ftfy, einops, av, huggingface-hub, tokenizers, diffusers, bitsandbytes, accelerate, transformers\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.5.3\n",
      "    Uninstalling safetensors-0.5.3:\n",
      "      Successfully uninstalled safetensors-0.5.3\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.11.0.86\n",
      "    Uninstalling opencv-python-4.11.0.86:\n",
      "      Successfully uninstalled opencv-python-4.11.0.86\n",
      "  Attempting uninstall: einops\n",
      "    Found existing installation: einops 0.8.1\n",
      "    Uninstalling einops-0.8.1:\n",
      "      Successfully uninstalled einops-0.8.1\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.32.2\n",
      "    Uninstalling huggingface-hub-0.32.2:\n",
      "      Successfully uninstalled huggingface-hub-0.32.2\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.4.0\n",
      "    Uninstalling accelerate-1.4.0:\n",
      "      Successfully uninstalled accelerate-1.4.0\n",
      "Successfully installed accelerate-1.6.0 av-14.0.1 bitsandbytes-0.45.4 diffusers-0.32.1 easydict-1.13 einops-0.7.0 ftfy-6.3.1 huggingface-hub-0.30.0 opencv-python-4.10.0.84 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.20.3 toml-0.10.2 transformers-4.46.3 voluptuous-0.15.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container 7978f230e246\n",
      " ---> 775ddeba02b9\n",
      "Step 10/10 : RUN pip install wandb\n",
      " ---> Running in 2e4acd64c9f4\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.20.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/site-packages (from wandb) (24.2)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.12/site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/site-packages (from wandb) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.29.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.6-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/site-packages (from wandb) (4.12.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.12/site-packages (from pydantic<3->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.20.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.2/23.2 MB 163.7 MB/s eta 0:00:00\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading sentry_sdk-2.29.1-py2.py3-none-any.whl (341 kB)\n",
      "Downloading setproctitle-1.3.6-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, gitdb, gitpython, wandb\n",
      "Successfully installed gitdb-4.0.12 gitpython-3.1.44 sentry-sdk-2.29.1 setproctitle-1.3.6 smmap-5.0.2 wandb-0.20.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container 2e4acd64c9f4\n",
      " ---> 2ce2c1526b7c\n",
      "Successfully built 2ce2c1526b7c\n",
      "Successfully tagged hunyuan-lora-taining-job:latest\n",
      "The push refers to repository [687912291502.dkr.ecr.us-west-2.amazonaws.com/hunyuan-lora-taining-job]\n",
      "ba96a7f8a513: Preparing\n",
      "08ac9caea82a: Preparing\n",
      "914343a3b7cd: Preparing\n",
      "72491320233c: Preparing\n",
      "5f90d10050bd: Preparing\n",
      "a093de062de0: Preparing\n",
      "8258e6ad8a7d: Preparing\n",
      "24c325fd1fcf: Preparing\n",
      "5b1c0b9bc842: Preparing\n",
      "70e4dc36b2a0: Preparing\n",
      "62a9902ccb5c: Preparing\n",
      "21eb8c4a4b9a: Preparing\n",
      "38114bb32027: Preparing\n",
      "0539acf30d51: Preparing\n",
      "a285f71ba745: Preparing\n",
      "4ca6fadf827a: Preparing\n",
      "5b03b951c8a4: Preparing\n",
      "208f5860a0a7: Preparing\n",
      "ec0383c296be: Preparing\n",
      "847751230e4d: Preparing\n",
      "796905bfb469: Preparing\n",
      "9ee008601a46: Preparing\n",
      "8d6d105c21f5: Preparing\n",
      "4e3fdc5e4d6c: Preparing\n",
      "e084e717424a: Preparing\n",
      "1b78ecebe6a4: Preparing\n",
      "4625540be79f: Preparing\n",
      "2a02d2bdb32b: Preparing\n",
      "8258e6ad8a7d: Waiting\n",
      "24c325fd1fcf: Waiting\n",
      "841ff51d7e8b: Preparing\n",
      "436a0763944e: Preparing\n",
      "9ccf259209da: Preparing\n",
      "0a2cb86de547: Preparing\n",
      "ad84c964bb80: Preparing\n",
      "ba60839a45ef: Preparing\n",
      "16e0d59a036a: Preparing\n",
      "1359458b2592: Preparing\n",
      "4defa32d7c73: Preparing\n",
      "f04bac04c649: Preparing\n",
      "2cbbf04c3d0c: Preparing\n",
      "5b1c0b9bc842: Waiting\n",
      "aca2e81a7ee2: Preparing\n",
      "8d3f433d3e6d: Preparing\n",
      "83a1523dc076: Preparing\n",
      "a093de062de0: Waiting\n",
      "b1073d6bdf44: Preparing\n",
      "70e4dc36b2a0: Waiting\n",
      "897c9bc30070: Preparing\n",
      "3c78875214d0: Preparing\n",
      "f1daa9f83fdc: Preparing\n",
      "f72f00af3d11: Preparing\n",
      "62a9902ccb5c: Waiting\n",
      "21eb8c4a4b9a: Waiting\n",
      "38114bb32027: Waiting\n",
      "cc9ee102691b: Preparing\n",
      "0539acf30d51: Waiting\n",
      "f0caebf6d886: Preparing\n",
      "a285f71ba745: Waiting\n",
      "782979f338e9: Preparing\n",
      "2573e0d81582: Preparing\n",
      "4ca6fadf827a: Waiting\n",
      "5b03b951c8a4: Waiting\n",
      "841ff51d7e8b: Waiting\n",
      "208f5860a0a7: Waiting\n",
      "436a0763944e: Waiting\n",
      "9ccf259209da: Waiting\n",
      "ec0383c296be: Waiting\n",
      "0a2cb86de547: Waiting\n",
      "ad84c964bb80: Waiting\n",
      "ba60839a45ef: Waiting\n",
      "e084e717424a: Waiting\n",
      "16e0d59a036a: Waiting\n",
      "796905bfb469: Waiting\n",
      "8d6d105c21f5: Waiting\n",
      "9ee008601a46: Waiting\n",
      "1359458b2592: Waiting\n",
      "1b78ecebe6a4: Waiting\n",
      "4e3fdc5e4d6c: Waiting\n",
      "4defa32d7c73: Waiting\n",
      "2a02d2bdb32b: Waiting\n",
      "f04bac04c649: Waiting\n",
      "2cbbf04c3d0c: Waiting\n",
      "f1daa9f83fdc: Waiting\n",
      "aca2e81a7ee2: Waiting\n",
      "8d3f433d3e6d: Waiting\n",
      "83a1523dc076: Waiting\n",
      "f72f00af3d11: Waiting\n",
      "b1073d6bdf44: Waiting\n",
      "f0caebf6d886: Waiting\n",
      "782979f338e9: Waiting\n",
      "897c9bc30070: Waiting\n",
      "3c78875214d0: Waiting\n",
      "2573e0d81582: Waiting\n",
      "72491320233c: Layer already exists\n",
      "a093de062de0: Layer already exists\n",
      "5f90d10050bd: Layer already exists\n",
      "8258e6ad8a7d: Layer already exists\n",
      "24c325fd1fcf: Layer already exists\n",
      "5b1c0b9bc842: Layer already exists\n",
      "70e4dc36b2a0: Layer already exists\n",
      "62a9902ccb5c: Layer already exists\n",
      "21eb8c4a4b9a: Layer already exists\n",
      "38114bb32027: Layer already exists\n",
      "0539acf30d51: Layer already exists\n",
      "a285f71ba745: Layer already exists\n",
      "4ca6fadf827a: Layer already exists\n",
      "914343a3b7cd: Pushed\n",
      "5b03b951c8a4: Layer already exists\n",
      "208f5860a0a7: Layer already exists\n",
      "847751230e4d: Layer already exists\n",
      "ec0383c296be: Layer already exists\n",
      "796905bfb469: Layer already exists\n",
      "4e3fdc5e4d6c: Layer already exists\n",
      "9ee008601a46: Layer already exists\n",
      "8d6d105c21f5: Layer already exists\n",
      "4625540be79f: Layer already exists\n",
      "2a02d2bdb32b: Layer already exists\n",
      "e084e717424a: Layer already exists\n",
      "1b78ecebe6a4: Layer already exists\n",
      "841ff51d7e8b: Layer already exists\n",
      "436a0763944e: Layer already exists\n",
      "9ccf259209da: Layer already exists\n",
      "0a2cb86de547: Layer already exists\n",
      "ba60839a45ef: Layer already exists\n",
      "ad84c964bb80: Layer already exists\n",
      "16e0d59a036a: Layer already exists\n",
      "f04bac04c649: Layer already exists\n",
      "4defa32d7c73: Layer already exists\n",
      "1359458b2592: Layer already exists\n",
      "aca2e81a7ee2: Layer already exists\n",
      "2cbbf04c3d0c: Layer already exists\n",
      "8d3f433d3e6d: Layer already exists\n",
      "83a1523dc076: Layer already exists\n",
      "b1073d6bdf44: Layer already exists\n",
      "897c9bc30070: Layer already exists\n",
      "3c78875214d0: Layer already exists\n",
      "f1daa9f83fdc: Layer already exists\n",
      "f72f00af3d11: Layer already exists\n",
      "cc9ee102691b: Layer already exists\n",
      "f0caebf6d886: Layer already exists\n",
      "782979f338e9: Layer already exists\n",
      "2573e0d81582: Layer already exists\n",
      "ba96a7f8a513: Pushed\n",
      "08ac9caea82a: Pushed\n",
      "latest: digest: sha256:2241d770ef35192d482344b2688ebc04214792c42db55fd656d67b8020cad0c7 size: 11014\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "algorithm_name=hunyuan-lora-taining-job\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "#load public ECR image\n",
    "#aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws\n",
    "\n",
    "# Log into Docker\n",
    "pwd=$(aws ecr get-login-password --region ${region})\n",
    "docker login --username AWS -p ${pwd} ${account}.dkr.ecr.${region}.amazonaws.com\n",
    "\n",
    "docker build -t ${algorithm_name} ./ -f ./Dockerfile\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4430a-6714-409c-bbef-f28ad569f1ae",
   "metadata": {},
   "source": [
    "## Train models with SageMaker training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86b7bee6-59b0-4170-a3aa-7823a8fa25af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "images_s3uri = 's3://{0}/hunyuan-lora-train/dataset/'.format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef957f93-c7d7-4c39-b82c-597574b3cf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: images/.ipynb_checkpoints/3-checkpoint.txt to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/.ipynb_checkpoints/3-checkpoint.txt\n",
      "upload: images/.ipynb_checkpoints/2-checkpoint.txt to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/.ipynb_checkpoints/2-checkpoint.txt\n",
      "upload: images/.ipynb_checkpoints/4-checkpoint.txt to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/.ipynb_checkpoints/4-checkpoint.txt\n",
      "upload: images/2.txt to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/2.txt\n",
      "upload: images/.ipynb_checkpoints/dataset-checkpoint.toml to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/.ipynb_checkpoints/dataset-checkpoint.toml\n",
      "upload: images/.ipynb_checkpoints/4-checkpoint.jpg to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/.ipynb_checkpoints/4-checkpoint.jpg\n",
      "upload: images/3.jpg to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/3.jpg\n",
      "upload: images/4.txt to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/4.txt\n",
      "upload: images/4.jpg to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/4.jpg\n",
      "upload: images/6.txt to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/6.txt\n",
      "upload: images/8.txt to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/8.txt\n",
      "upload: images/5.jpg to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/5.jpg\n",
      "upload: images/dataset.toml to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/dataset.toml\n",
      "upload: images/5.txt to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/5.txt\n",
      "upload: images/.ipynb_checkpoints/2-checkpoint.jpg to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/.ipynb_checkpoints/2-checkpoint.jpg\n",
      "upload: images/3.txt to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/3.txt\n",
      "upload: images/.ipynb_checkpoints/3-checkpoint.jpg to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/.ipynb_checkpoints/3-checkpoint.jpg\n",
      "upload: images/2.jpg to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/2.jpg\n",
      "upload: images/8.jpg to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/8.jpg\n",
      "upload: images/6.jpg to s3://sagemaker-us-west-2-687912291502/hunyuan-lora-train/dataset/6.jpg\n"
     ]
    }
   ],
   "source": [
    "# Copy training dataset to S3 bucket\n",
    "!aws s3 cp images $images_s3uri --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7925ec1f",
   "metadata": {},
   "source": [
    "***You need to provide your own \"wandb_api_key\" for below scripts***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d211af39-31e9-40b9-8d77-51fdaaddedc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docker_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/hunyuan-lora-taining-job'.format(account_id, region_name)\n",
    "instance_type = 'ml.g6e.xlarge'\n",
    "\n",
    "environment = {'LD_LIBRARY_PATH': \"${LD_LIBRARY_PATH}:/opt/conda/lib/python3.11/site-packages/nvidia/nvjitlink/lib/\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b10c313-3151-42b4-a9d7-0b3ef9a7dc43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'687912291502.dkr.ecr.us-west-2.amazonaws.com/hunyuan-lora-taining-job'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d2ca0d-d5a1-4f8b-b085-37311f88a70e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/04/25 23:17:00] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/04/25 23:17:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=205000;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=31756;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1053\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1053</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         hunyuan-lora-taining-job-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-06-04-23-17-00-837                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=49187;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=806078;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1053\u001b\\\u001b[2m1053\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         hunyuan-lora-taining-job-\u001b[1;36m2025\u001b[0m-06-04-23-17-00-837                       \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-04 23:17:01 Starting - Starting the training job\n",
      "2025-06-04 23:17:01 Pending - Training job waiting for capacity........................................................"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "inputs = {\n",
    "    'lora_hunyuan': images_s3uri,\n",
    "}\n",
    "\n",
    "estimator = Estimator(\n",
    "    entry_point=\"train_hunyuan_lora.sh\",\n",
    "    role = role,\n",
    "    instance_count=1,\n",
    "    instance_type = instance_type,\n",
    "    image_uri = docker_image_uri,\n",
    "    environment=environment,\n",
    "    disable_output_compression = True,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    enable_remote_debug=True,\n",
    "    \n",
    ")\n",
    "estimator.fit(inputs=inputs,wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98878f2c-3b92-42b9-a01e-40a418e083b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### remote debug连接training job ssm容器实例\n",
    "import time\n",
    "job_name=\"lora-lora-taining-job-\"+str(int(time.time()))\n",
    "training_job_info = sagemaker_session.describe_training_job(job_name)\n",
    "print(training_job_info)\n",
    "#!aws ssm start-session --target sagemaker-training-job:${job_name}_algo-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b2b7d-157e-4b5d-a592-7264b564663e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data = estimator.model_data\n",
    "model_s3_path = model_data['S3DataSource']['S3Uri']\n",
    "print(\"Model artifact saved at:\", \"\\n\"+model_s3_path+\"\\n\")\n",
    "!aws s3 ls {model_s3_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae8aad-b875-45f8-940a-f0d053e3d374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
