{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0013ee3b-6a7f-4625-a110-4f122e698925",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Download training dataset and Flux model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4408032-5d2f-4bcf-a3b8-15cf07a88249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "flux_lora_training = \"./flux_lora_training\"\n",
    "os.makedirs(flux_lora_training, exist_ok=True)\n",
    "\n",
    "%cd flux_lora_training/\n",
    "\n",
    "train_image_dir = \"./images\"\n",
    "docker_file_dir = \"./dockerfile\"\n",
    "os.makedirs(train_image_dir, exist_ok=True)\n",
    "os.makedirs(docker_file_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3741fbc-2b49-462a-b672-6bd5926c011a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "metadata_file = os.path.join(train_image_dir, 'metadata.jsonl')\n",
    "with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        filename = data['file_name'].split('.')[0]\n",
    "        text = data['text']\n",
    "        output_file = os.path.join(train_image_dir, f'{filename}.txt')\n",
    "        with open(output_file, 'w', encoding='utf-8') as txt_file:\n",
    "            txt_file.write(text)\n",
    "os.remove(metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c21fbc-8db1-471a-a89f-1cd720add707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac1186-fad3-4c45-ad6e-a4b543e6a349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login, hf_hub_download\n",
    "\n",
    "# You need to replace below with your own. \n",
    "access_token = \"******\"\n",
    "login(access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c77cb4-f3cd-4acd-906f-a04c5d586080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = \"./models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "model_vae_repo_id = \"black-forest-labs/FLUX.1-dev\"\n",
    "model_vae_files = [\"flux1-dev.safetensors\", \"ae.safetensors\"]\n",
    "text_encoders_repo_id = \"comfyanonymous/flux_text_encoders\"\n",
    "text_encoders_files = [\"clip_l.safetensors\", \"t5xxl_fp16.safetensors\"]\n",
    "\n",
    "for file in model_vae_files:\n",
    "    hf_hub_download(model_vae_repo_id, local_dir=model_dir, filename=file)\n",
    "for file in text_encoders_files:\n",
    "    hf_hub_download(text_encoders_repo_id, local_dir=model_dir, filename=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74cd90-9ef6-45a6-a302-f4acdaeaf9a6",
   "metadata": {},
   "source": [
    "## 2. Prepare training config files and Dockerfile(docker image for training job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eeb11e-2e1e-4224-a624-7d7ab474fe34",
   "metadata": {},
   "source": [
    "***Refer \"dataset-example.toml\" to configure your own .toml file***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1536c989-4d31-4b73-bc4c-a4a077b7b355",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./images/dataset.toml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./images/dataset.toml\n",
    "[general]\n",
    "enable_bucket = true\n",
    "\n",
    "# DreamBooth caption based datasets\n",
    "[[datasets]]\n",
    "resolution = 512\n",
    "batch_size = 2\n",
    "caption_extension = '.txt'\n",
    "keep_tokens = 0\n",
    "\n",
    "  [[datasets.subsets]]\n",
    "  image_dir = '/opt/ml/input/data/images/'\n",
    "  num_repeats = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e672a660-3795-4645-a719-6a53b46546eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### other alternative metadata type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a340910-3cfb-471a-977f-9e71201bae8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%writefile ./images/dataset.toml\n",
    "#[general]\n",
    "#enable_bucket = true\n",
    "#caption_extension = '.txt'\n",
    "#keep_tokens = 0\n",
    "#\n",
    "#[[datasets]]\n",
    "#resolution = 1024\n",
    "## min_bucket_reso = 640\n",
    "## max_bucket_reso = 1536\n",
    "#bucket_reso_steps = 32\n",
    "#batch_size = 2\n",
    "#\n",
    "#[[datasets.subsets]]\n",
    "#image_dir = '/opt/ml/input/data/images'\n",
    "\n",
    "#[general]\n",
    "#enable_bucket = true\n",
    "#caption_extension = '.txt'\n",
    "#keep_tokens = 0\n",
    "#[[datasets]]\n",
    "#resolution = [768, 768]\n",
    "#batch_size = 2\n",
    "#\n",
    "#  [[datasets.subsets]]\n",
    "#  image_dir = '/opt/ml/input/data/images/'\n",
    "#  metadata_file = '/opt/ml/input/data/images/metadata.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72f96139-0e61-4000-a16a-b5ce0fde6e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%writefile ./images/sample_prompt.toml\n",
    "#[prompt]\n",
    "#sample_steps = 20\n",
    "#width = 1024\n",
    "#height = 1024\n",
    "#\n",
    "#[[prompt.subset]]\n",
    "#prompt = \"wta, 1girl, looking at viewer, blue hair, short twintails, hair ornament, blue eyes, blush, smile, open mouth, shirt, skirt, kneehighs, brown footwear, standing, solo\"\n",
    "#seed = 1000\n",
    "#[[prompt.subset]]\n",
    "#prompt = \"wta, 1girl, looking at viewer, blue hair, short twintails, hair ornament, blue eyes, blush, smile, open mouth, shirt, skirt, kneehighs, brown footwear, standing, solo\"\n",
    "#seed = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4c65b11-0fdf-4768-9096-e934f022c153",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./dockerfile/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./dockerfile/Dockerfile\n",
    "FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker\n",
    "\n",
    "ENV PATH=\"/opt/ml/code:${PATH}\"\n",
    "ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
    "ENV DEBIAN_FRONTEND noninteractive\n",
    "\n",
    "RUN git clone -b sd3 https://github.com/kohya-ss/sd-scripts /opt/ml/code\n",
    "\n",
    "WORKDIR /opt/ml/code\n",
    "\n",
    "RUN mv flux_train_network.py flux_train_network && \\\n",
    "    sed -i 's/-e \\./\\./g' requirements.txt && \\\n",
    "    pip3 install torch==2.4.0 torchvision==0.19.0 --index-url https://download.pytorch.org/whl/cu124 && \\\n",
    "    pip install -r requirements.txt && \\\n",
    "    pip install wandb && \\\n",
    "    pip uninstall transformer-engine -y # Solve error of \"transformer_engine_extensions.cpython-311-x86_64-linux-gnu.so: undefined symbol\"\n",
    "\n",
    "# RUN mkdir -p images/\n",
    "\n",
    "# COPY ./images/* ./images/\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "ENV SAGEMAKER_PROGRAM accelerate.commands.launch --mixed_precision bf16 --num_cpu_threads_per_process 1 flux_train_network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469005ba-e788-425b-aadb-c729e576beb5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Build docker image and push to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f9456-cef0-4d30-9996-43ff8365416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You should change below region code to the region you used, here sample is use us-west-2\n",
    "!aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-west-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2244ef-74e1-438d-a176-e48015530eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "algorithm_name=flux-lora-taining-job\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "#load public ECR image\n",
    "#aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws\n",
    "\n",
    "# Log into Docker\n",
    "pwd=$(aws ecr get-login-password --region ${region})\n",
    "docker login --username AWS -p ${pwd} ${account}.dkr.ecr.${region}.amazonaws.com\n",
    "\n",
    "docker build -t ${algorithm_name} ./dockerfile\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4430a-6714-409c-bbef-f28ad569f1ae",
   "metadata": {},
   "source": [
    "## 5. Train models with SageMaker training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86b7bee6-59b0-4170-a3aa-7823a8fa25af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "images_s3uri = 's3://{0}/flux-lora-train/dataset/'.format(bucket)\n",
    "models_s3uri = 's3://{0}/flux-lora-train/models/'.format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef957f93-c7d7-4c39-b82c-597574b3cf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: images/.ipynb_checkpoints/metadata-checkpoint.jsonl to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/.ipynb_checkpoints/metadata-checkpoint.jsonl\n",
      "upload: images/2.txt to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/2.txt\n",
      "upload: images/4.txt to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/4.txt\n",
      "upload: images/5.jpg to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/5.jpg\n",
      "upload: images/.ipynb_checkpoints/5-checkpoint.jpg to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/.ipynb_checkpoints/5-checkpoint.jpg\n",
      "upload: images/6.txt to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/6.txt\n",
      "upload: images/5.txt to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/5.txt\n",
      "upload: images/.ipynb_checkpoints/dataset-checkpoint.toml to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/.ipynb_checkpoints/dataset-checkpoint.toml\n",
      "upload: images/3.txt to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/3.txt\n",
      "upload: images/8.txt to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/8.txt\n",
      "upload: images/.ipynb_checkpoints/6-checkpoint.jpg to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/.ipynb_checkpoints/6-checkpoint.jpg\n",
      "upload: images/2.jpg to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/2.jpg\n",
      "upload: images/4.jpg to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/4.jpg\n",
      "upload: images/6.jpg to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/6.jpg\n",
      "upload: images/.ipynb_checkpoints/2-checkpoint.jpg to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/.ipynb_checkpoints/2-checkpoint.jpg\n",
      "upload: images/.ipynb_checkpoints/3-checkpoint.jpg to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/.ipynb_checkpoints/3-checkpoint.jpg\n",
      "upload: images/3.jpg to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/3.jpg\n",
      "upload: images/8.jpg to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/8.jpg\n",
      "upload: images/dataset.toml to s3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/dataset.toml\n"
     ]
    }
   ],
   "source": [
    "# Copy training dataset to S3 bucket\n",
    "\n",
    "!aws s3 cp images $images_s3uri --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b323a4e2-fdd7-4909-a97f-1a2a714f3000",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The user-provided path models does not exist.\n"
     ]
    }
   ],
   "source": [
    "# Copy flux model files to S3 bucket\n",
    "\n",
    "!aws s3 cp models $models_s3uri --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7925ec1f",
   "metadata": {},
   "source": [
    "***You need to provide your own \"wandb_api_key\" for below scripts***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d211af39-31e9-40b9-8d77-51fdaaddedc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained_model_name_or_path /opt/ml/input/data/models/flux1-dev.safetensors\n",
      "clip_l /opt/ml/input/data/models/clip_l.safetensors\n",
      "t5xxl /opt/ml/input/data/models/t5xxl_fp16.safetensors\n",
      "ae /opt/ml/input/data/models/ae.safetensors\n",
      "save_model_as safetensors\n",
      "sdpa \n",
      "persistent_data_loader_workers \n",
      "max_data_loader_n_workers 2\n",
      "gradient_checkpointing \n",
      "mixed_precision bf16\n",
      "save_precision bf16\n",
      "full_bf16 \n",
      "network_module networks.lora_flux\n",
      "network_dim 64\n",
      "network_alpha 32\n",
      "lr_scheduler cosine_with_restarts\n",
      "lr_scheduler_num_cycles 1\n",
      "optimizer_type prodigy\n",
      "optimizer_args safeguard_warmup=True\n",
      "learning_rate 0.0001\n",
      "cache_latents_to_disk \n",
      "cache_text_encoder_outputs \n",
      "cache_text_encoder_outputs_to_disk \n",
      "fp8_base \n",
      "highvram \n",
      "max_train_steps 540\n",
      "save_every_n_steps 120\n",
      "dataset_config /opt/ml/input/data/images/dataset.toml\n",
      "output_dir /opt/ml/model/\n",
      "output_name flux_lora_wta\n",
      "timestep_sampling shift\n",
      "discrete_flow_shift 3.1582\n",
      "model_prediction_type raw\n",
      "guidance_scale 1\n",
      "t5xxl_max_token_length 512\n",
      "sample_sampler euler_a\n",
      "logging_dir /opt/ml/code/logs\n",
      "log_with all\n",
      "log_tracker_name flux_lora_wta\n",
      "log_config \n",
      "wandb_api_key 298b59ce8a416fd45b5fa9ffc17fe72327854e0c\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    for (k, v) in hyperparameters.items():\n",
    "        print(k, v)\n",
    "    return {k: json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "docker_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/flux-lora-taining-job'.format(account_id, region_name)\n",
    "instance_type = 'ml.g5.2xlarge'\n",
    "\n",
    "lora_name = \"flux_lora_wta\"\n",
    "output_dir=\"/opt/ml/model/\"\n",
    "wandb_api_key = \"*******\" # Provide your wandb key\n",
    "\n",
    "environment = {'LD_LIBRARY_PATH': \"${LD_LIBRARY_PATH}:/opt/conda/lib/python3.11/site-packages/nvidia/nvjitlink/lib/\"}\n",
    "\n",
    "hyperparameters = {\n",
    "                    'pretrained_model_name_or_path': '/opt/ml/input/data/models/flux1-dev.safetensors',\n",
    "                    'clip_l': '/opt/ml/input/data/models/clip_l.safetensors',\n",
    "                    't5xxl': '/opt/ml/input/data/models/t5xxl_fp16.safetensors',\n",
    "                    'ae': '/opt/ml/input/data/models/ae.safetensors',\n",
    "                    'save_model_as': 'safetensors',\n",
    "                    'sdpa': '',\n",
    "                    'persistent_data_loader_workers': '',\n",
    "                    'max_data_loader_n_workers': 2,\n",
    "                    'gradient_checkpointing': '',\n",
    "                    'mixed_precision': 'bf16',\n",
    "                    'save_precision': 'bf16',\n",
    "                    'full_bf16': '',\n",
    "                    'network_module': 'networks.lora_flux',\n",
    "                    'network_dim': 64,\n",
    "                    'network_alpha': 32,\n",
    "                    'lr_scheduler': 'cosine_with_restarts',\n",
    "                    'lr_scheduler_num_cycles': 1,\n",
    "                    'optimizer_type': 'prodigy',\n",
    "                    'optimizer_args': 'safeguard_warmup=True',\n",
    "                    'learning_rate': 1e-4,\n",
    "                    'cache_latents_to_disk': '',\n",
    "                    'cache_text_encoder_outputs': '',\n",
    "                    'cache_text_encoder_outputs_to_disk': '',\n",
    "                    'fp8_base': '',\n",
    "                    'highvram': '',\n",
    "                    'max_train_steps': 540,\n",
    "                    'save_every_n_steps': 120,\n",
    "                    'dataset_config': '/opt/ml/input/data/images/dataset.toml',\n",
    "                    'output_dir': output_dir,\n",
    "                    'output_name': lora_name,\n",
    "                    'timestep_sampling': 'shift',\n",
    "                    'discrete_flow_shift': 3.1582,\n",
    "                    'model_prediction_type': 'raw',\n",
    "                    'guidance_scale': 1,\n",
    "                    't5xxl_max_token_length': 512,\n",
    "                    #'sample_every_n_steps': 120,\n",
    "                    #'sample_prompts': '/opt/ml/input/data/images/sample_prompt.toml',\n",
    "                    'sample_sampler': 'euler_a',\n",
    "                    'logging_dir': '/opt/ml/code/logs',\n",
    "                    'log_with': 'all',\n",
    "                    'log_tracker_name': lora_name,\n",
    "                    'log_config':'',\n",
    "                    'wandb_api_key': wandb_api_key\n",
    "}\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "28d2ca0d-d5a1-4f8b-b085-37311f88a70e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: flux-lora-taining-job-2024-09-01-14-34-16-619\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "inputs = {\n",
    "    'images': images_s3uri,\n",
    "    'models': models_s3uri\n",
    "}\n",
    "\n",
    "estimator = Estimator(\n",
    "    role = role,\n",
    "    instance_count=1,\n",
    "    instance_type = instance_type,\n",
    "    image_uri = docker_image_uri,\n",
    "    hyperparameters = hyperparameters,\n",
    "    environment=environment,\n",
    "    disable_output_compression = True,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    enable_remote_debug=True,\n",
    "    \n",
    ")\n",
    "estimator.fit(inputs=inputs,wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98878f2c-3b92-42b9-a01e-40a418e083b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TrainingJobName': 'flux-lora-taining-job-2024-09-01-13-36-04-512', 'TrainingJobArn': 'arn:aws:sagemaker:us-west-2:687912291502:training-job/flux-lora-taining-job-2024-09-01-13-36-04-512', 'ModelArtifacts': {'S3ModelArtifacts': 's3://sagemaker-us-west-2-687912291502/flux-lora-taining-job-2024-09-01-13-36-04-512/output/model'}, 'TrainingJobStatus': 'Completed', 'SecondaryStatus': 'Completed', 'HyperParameters': {'ae': '\"/opt/ml/input/data/models/ae.safetensors\"', 'cache_latents_to_disk': '\"\"', 'cache_text_encoder_outputs': '\"\"', 'cache_text_encoder_outputs_to_disk': '\"\"', 'clip_l': '\"/opt/ml/input/data/models/clip_l.safetensors\"', 'dataset_config': '\"/opt/ml/input/data/images/dataset.toml\"', 'discrete_flow_shift': '3.1582', 'fp8_base': '\"\"', 'full_bf16': '\"\"', 'gradient_checkpointing': '\"\"', 'guidance_scale': '1', 'highvram': '\"\"', 'learning_rate': '1.0', 'log_config': '\"\"', 'log_tracker_name': '\"flux_lora_wta\"', 'log_with': '\"all\"', 'logging_dir': '\"/opt/ml/code/logs\"', 'lr_scheduler': '\"cosine_with_restarts\"', 'lr_scheduler_num_cycles': '1', 'max_data_loader_n_workers': '2', 'max_train_steps': '540', 'mixed_precision': '\"bf16\"', 'model_prediction_type': '\"raw\"', 'network_alpha': '32', 'network_dim': '64', 'network_module': '\"networks.lora_flux\"', 'optimizer_args': '\"safeguard_warmup=True\"', 'optimizer_type': '\"prodigy\"', 'output_dir': '\"/opt/ml/model/\"', 'output_name': '\"flux_lora_wta\"', 'persistent_data_loader_workers': '\"\"', 'pretrained_model_name_or_path': '\"/opt/ml/input/data/models/flux1-dev.safetensors\"', 'sample_sampler': '\"euler_a\"', 'save_every_n_steps': '120', 'save_model_as': '\"safetensors\"', 'save_precision': '\"bf16\"', 'sdpa': '\"\"', 't5xxl': '\"/opt/ml/input/data/models/t5xxl_fp16.safetensors\"', 't5xxl_max_token_length': '512', 'timestep_sampling': '\"shift\"', 'wandb_api_key': '\"298b59ce8a416fd45b5fa9ffc17fe72327854e0c\"'}, 'AlgorithmSpecification': {'TrainingImage': '687912291502.dkr.ecr.us-west-2.amazonaws.com/flux-lora-taining-job', 'TrainingInputMode': 'File', 'EnableSageMakerMetricsTimeSeries': False}, 'RoleArn': 'arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123', 'InputDataConfig': [{'ChannelName': 'images', 'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-west-2-687912291502/flux-lora-train/dataset/', 'S3DataDistributionType': 'FullyReplicated'}}, 'CompressionType': 'None', 'RecordWrapperType': 'None'}, {'ChannelName': 'models', 'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-west-2-687912291502/flux-lora-train/models/', 'S3DataDistributionType': 'FullyReplicated'}}, 'CompressionType': 'None', 'RecordWrapperType': 'None'}], 'OutputDataConfig': {'KmsKeyId': '', 'S3OutputPath': 's3://sagemaker-us-west-2-687912291502/', 'CompressionType': 'NONE'}, 'ResourceConfig': {'InstanceType': 'ml.g5.4xlarge', 'InstanceCount': 1, 'VolumeSizeInGB': 30}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'CreationTime': datetime.datetime(2024, 9, 1, 13, 36, 4, 697000, tzinfo=tzlocal()), 'TrainingStartTime': datetime.datetime(2024, 9, 1, 13, 36, 59, 928000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 9, 1, 14, 32, 23, 270000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 9, 1, 14, 32, 23, 463000, tzinfo=tzlocal()), 'SecondaryStatusTransitions': [{'Status': 'Starting', 'StartTime': datetime.datetime(2024, 9, 1, 13, 36, 4, 697000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 9, 1, 13, 36, 5, 185000, tzinfo=tzlocal()), 'StatusMessage': 'Starting the training job'}, {'Status': 'Pending', 'StartTime': datetime.datetime(2024, 9, 1, 13, 36, 5, 185000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 9, 1, 13, 36, 59, 928000, tzinfo=tzlocal()), 'StatusMessage': 'Preparing the instances for training'}, {'Status': 'Downloading', 'StartTime': datetime.datetime(2024, 9, 1, 13, 36, 59, 928000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 9, 1, 13, 51, 12, 495000, tzinfo=tzlocal()), 'StatusMessage': 'Downloading the training image'}, {'Status': 'Training', 'StartTime': datetime.datetime(2024, 9, 1, 13, 51, 12, 495000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 9, 1, 14, 32, 0, 770000, tzinfo=tzlocal()), 'StatusMessage': 'Training image download completed. Training in progress.'}, {'Status': 'Uploading', 'StartTime': datetime.datetime(2024, 9, 1, 14, 32, 0, 770000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 9, 1, 14, 32, 23, 270000, tzinfo=tzlocal()), 'StatusMessage': 'Uploading generated training model'}, {'Status': 'Completed', 'StartTime': datetime.datetime(2024, 9, 1, 14, 32, 23, 270000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 9, 1, 14, 32, 23, 270000, tzinfo=tzlocal()), 'StatusMessage': 'Training job completed'}], 'EnableNetworkIsolation': False, 'EnableInterContainerTrafficEncryption': False, 'EnableManagedSpotTraining': False, 'TrainingTimeInSeconds': 3324, 'BillableTimeInSeconds': 3324, 'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-us-west-2-687912291502/', 'CollectionConfigurations': []}, 'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-us-west-2-687912291502/', 'ProfilingIntervalInMilliseconds': 500, 'DisableProfiler': False}, 'ProfilingStatus': 'Enabled', 'Environment': {'LD_LIBRARY_PATH': '${LD_LIBRARY_PATH}:/opt/conda/lib/python3.11/site-packages/nvidia/nvjitlink/lib/'}, 'ResponseMetadata': {'RequestId': '0a53da65-2657-4e47-a542-81ddb02ca08c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '0a53da65-2657-4e47-a542-81ddb02ca08c', 'content-type': 'application/x-amz-json-1.1', 'content-length': '4704', 'date': 'Sun, 01 Sep 2024 14:34:17 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "### remote debug连接training job ssm容器实例\n",
    "job_name=\"flux-lora-taining-job-2024-09-01-13-36-04-512\"\n",
    "training_job_info = sagemaker_session.describe_training_job(job_name)\n",
    "print(training_job_info)\n",
    "#!aws ssm start-session --target sagemaker-training-job:${job_name}_algo-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "854b2b7d-157e-4b5d-a592-7264b564663e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact saved at: \n",
      "s3://sagemaker-us-west-2-687912291502/flux-lora-taining-job-2024-09-01-13-36-04-512/output/model/\n",
      "\n",
      "2024-09-01 14:32:08  634008304 flux_lora_wta-step00000120.safetensors\n",
      "2024-09-01 14:32:10  634008304 flux_lora_wta-step00000240.safetensors\n",
      "2024-09-01 14:32:06  634008304 flux_lora_wta-step00000360.safetensors\n",
      "2024-09-01 14:32:12  634008304 flux_lora_wta-step00000480.safetensors\n",
      "2024-09-01 14:32:17  634008304 flux_lora_wta.safetensors\n"
     ]
    }
   ],
   "source": [
    "model_data = estimator.model_data\n",
    "model_s3_path = model_data['S3DataSource']['S3Uri']\n",
    "print(\"Model artifact saved at:\", \"\\n\"+model_s3_path+\"\\n\")\n",
    "!aws s3 ls {model_s3_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "438f3555-d9c2-40cc-a513-aa6c6447d222",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lora weight is saved at: \n",
      "s3://sagemaker-us-west-2-687912291502/flux-lora-taining-job-2024-09-01-13-36-04-512/output/model/flux_lora_wta.safetensors\n"
     ]
    }
   ],
   "source": [
    "# You can change the applied lora weight by changing lora weight name\n",
    "\n",
    "lora_s3_path = model_s3_path + 'flux_lora_wta.safetensors'\n",
    "print (\"Lora weight is saved at:\", \"\\n\"+lora_s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd20b3-42fb-40de-89c4-616480b2ffcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
